plugins {
    id 'java'
}

group 'com.icoffiel'
version '1.0-SNAPSHOT'

repositories {
    mavenCentral()
}

dependencies {
    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.1'
    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.1'
}

test {
    useJUnitPlatform()
}

tasks.register('addConnectors') {
    description 'Adds the connectors to Kafka Connect'
    group 'kafka connect'
    dependsOn 'addSystemsConnector', 'addGamesConnector', 'addSystemsSink'
}

// TODO
//  - Move these into their own gradle file?
//  - Move these into the systems and games modules and run on startup?

import groovy.json.JsonSlurper
import groovy.json.JsonOutput

tasks.register('addSystemsConnector') {
    description 'Adds the System DB Source Connector to Kafka Connect'
    group 'kafka connect'
    doLast {
        def req = connectorsRequest(
            sourceRequestBody(
                "SystemsSourceConnector",
                "systems",
                "systems",
                "system_entity",
                "systems_sql_",
            )
        )

        def resp = new JsonSlurper().parseText(req.getInputStream().getText())
        logger.quiet "Response: ${resp}"
    }
}

tasks.register('addGamesConnector') {
    description 'Adds the Game DB Source Connector to Kafka Connect'
    group 'kafka connect'
    doLast {
        def req = connectorsRequest(
            sourceRequestBody(
                "GamesSourceConnector",
                "games",
                "games",
                "game_entity",
                "games_sql_",
            )
        )

        def resp = new JsonSlurper().parseText(req.getInputStream().getText())
        logger.quiet "Response: ${resp}"
    }
}

tasks.register('addSystemsSink') {
    description 'Adds the Systems DB Sink to Kafka Connect'
    group 'kafka connect'
    doLast {
        def body = [
                name: "SystemsToGameSink",
                config: [
                        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
                        "topics": "systems_sql_system_entity",

                        "connection.password": "games",
                        "connection.user": "games",
                        "connection.url": "jdbc:postgresql://postgres:5432/games",
                        "fields.whitelist": "id,name",
                        "table.name.format": "kafka_\${topic}",

                        "auto.evolve": "false",
                        "auto.create": "false",
                        "batch.size": "3000",
                        "insert.mode": "upsert",
                        "max.retries": "10",
                        "pk.mode": "record_value",
                        "pk.fields": "id",
                        "retry.backoff.ms": "3000",
                        "tasks.max": "1",
                ]
        ]
        def req = connectorsRequest(body)

        def resp = new JsonSlurper().parseText(req.getInputStream().getText())
        logger.quiet "Response: ${resp}"
    }
}

private static LinkedHashMap<String, Serializable> sourceRequestBody(String name, String user, String password, String table, String topicPrefix) {
    return [
            name  : name,
            config: [
                    "connector.class"            : "io.confluent.connect.jdbc.JdbcSourceConnector",

                    // Connection Properties
                    "connection.url"             : "jdbc:postgresql://postgres:5432/$user",
                    "connection.user"            : user,
                    "connection.password"        : password,

                    // Table configuration
                    "table.whitelist"            : table,

                    // Mode configuration
                    "mode"                       : "timestamp+incrementing", // Allows for both inserts and updates
                    "incrementing.column.name"   : "id",
                    "timestamp.column.name"      : "modified_date",

                    // Topic configuration
                    "tasks.max"                  : "1",
                    "topic.prefix"               : topicPrefix,

                    // Setup the Key for the topics
                    "transforms"                 : "createKey",
                    "transforms.createKey.type"  : "org.apache.kafka.connect.transforms.ValueToKey",
                    "transforms.createKey.fields": "id",
            ]
    ]
}


private static URLConnection connectorsRequest(LinkedHashMap<String, Serializable> body) {
    def req = new URL('http://localhost:8083/connectors/').openConnection()
    req.setRequestMethod("POST")
    req.setRequestProperty("Content-Type", "application/json; charset=UTF-8")
    req.setDoOutput(true)
    req.getOutputStream().write(JsonOutput.toJson(body).getBytes("UTF-8"))

    return req
}